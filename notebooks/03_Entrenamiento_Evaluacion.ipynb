{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cfb648",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectKBest,RFE, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "368b0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Lectura de datos de restaurantes de Madrid.\n",
    "'''\n",
    "restaurantes = pd.read_csv('../data/processed/restaurantes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e94317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes.drop(['nombre_restaurante', 'place_id', \n",
    "                   'direccion', 'tipo_cocina',\n",
    "                   'rating', 'user_ratings_total'\n",
    "                   ], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054f4e7",
   "metadata": {},
   "source": [
    "# Reg Lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448cbcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=81, poly__degree=3, scaler=StandardScaler(); total time= 2.0min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=81, poly__degree=3, scaler=StandardScaler(); total time= 1.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=81, poly__degree=3, scaler=StandardScaler(); total time= 1.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=81, poly__degree=3, scaler=StandardScaler(); total time= 1.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=81, poly__degree=3, scaler=StandardScaler(); total time= 1.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=46, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=46, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=46, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=46, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=46, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=1, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=1, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=1, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=1, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=1, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=96, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=96, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=96, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=96, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=96, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=96, poly__degree=2, scaler=passthrough; total time=   1.6s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=96, poly__degree=2, scaler=passthrough; total time=   1.8s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=96, poly__degree=2, scaler=passthrough; total time=   1.9s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=96, poly__degree=2, scaler=passthrough; total time=   1.9s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=96, poly__degree=2, scaler=passthrough; total time=   1.9s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=76, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=76, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=76, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=76, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=76, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=151, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=151, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=151, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=151, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=151, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=86, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=86, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=86, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=86, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=86, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=2, scaler=MinMaxScaler(); total time=   3.2s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=2, scaler=MinMaxScaler(); total time=   2.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=2, scaler=MinMaxScaler(); total time=   2.2s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=2, scaler=MinMaxScaler(); total time=   2.2s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=2, scaler=MinMaxScaler(); total time=   2.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=141, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=141, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=141, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=141, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=141, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.9min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.9min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=86, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=86, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=86, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=86, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=86, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=41, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=41, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=41, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=41, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=41, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=136, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=136, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=136, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=136, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=136, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=16, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=16, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=16, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=16, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=16, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=61, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=61, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=61, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=61, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=61, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=166, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=166, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=166, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=166, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=166, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=131, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=131, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=131, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=131, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=131, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=76, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=76, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=76, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=76, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=76, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=166, poly__degree=2, scaler=passthrough; total time=   1.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=166, poly__degree=2, scaler=passthrough; total time=   1.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=166, poly__degree=2, scaler=passthrough; total time=   1.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=166, poly__degree=2, scaler=passthrough; total time=   2.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=166, poly__degree=2, scaler=passthrough; total time=   2.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=146, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=146, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=146, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=146, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=146, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.7min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.7min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=1, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=1, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=1, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=1, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=1, poly__degree=1, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.8, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=16, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=16, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=16, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=16, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=16, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=26, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=26, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=26, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=26, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=26, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=111, poly__degree=1, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=111, poly__degree=1, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=111, poly__degree=1, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=111, poly__degree=1, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=111, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=171, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=171, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=171, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=171, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=171, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.6s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.6s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.1, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.75, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.75, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.75, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.75, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.75, pca__n_components=146, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=116, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=116, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=116, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=116, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=116, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.716e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.624e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.472e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.528e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.318e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=3, scaler=MinMaxScaler(); total time=  38.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=3, scaler=MinMaxScaler(); total time=  43.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=3, scaler=MinMaxScaler(); total time=  38.5s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=3, scaler=MinMaxScaler(); total time=  37.5s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=1, poly__degree=3, scaler=MinMaxScaler(); total time=  39.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.646e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=156, poly__degree=3, scaler=passthrough; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.496e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=156, poly__degree=3, scaler=passthrough; total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.476e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=156, poly__degree=3, scaler=passthrough; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=156, poly__degree=3, scaler=passthrough; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=156, poly__degree=3, scaler=passthrough; total time= 2.7min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=96, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=96, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=96, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=96, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.5, pca__n_components=96, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=131, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=131, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=131, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=131, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.25, pca__n_components=131, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=1, pca__n_components=156, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=1, pca__n_components=156, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=1, pca__n_components=156, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=1, pca__n_components=156, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=1, pca__n_components=156, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.6s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.25, pca__n_components=6, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=81, poly__degree=1, scaler=passthrough; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.692e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.554e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=81, poly__degree=1, scaler=passthrough; total time=   0.2s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=81, poly__degree=1, scaler=passthrough; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.464e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=81, poly__degree=1, scaler=passthrough; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.373e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=81, poly__degree=1, scaler=passthrough; total time=   0.1s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=156, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=156, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=156, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=156, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=156, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.9, pca__n_components=106, poly__degree=2, scaler=passthrough; total time=   2.6s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.9, pca__n_components=106, poly__degree=2, scaler=passthrough; total time=   2.3s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.9, pca__n_components=106, poly__degree=2, scaler=passthrough; total time=   3.1s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.9, pca__n_components=106, poly__degree=2, scaler=passthrough; total time=   2.5s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0.9, pca__n_components=106, poly__degree=2, scaler=passthrough; total time=   2.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.75, pca__n_components=171, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.75, pca__n_components=171, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.75, pca__n_components=171, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.75, pca__n_components=171, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.75, pca__n_components=171, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=1, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=StandardScaler(); total time=   0.9s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=StandardScaler(); total time=   0.9s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=StandardScaler(); total time=   1.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=StandardScaler(); total time=   1.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=StandardScaler(); total time=   0.9s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.75, pca__n_components=21, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.75, pca__n_components=21, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.75, pca__n_components=21, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.75, pca__n_components=21, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.75, pca__n_components=21, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0, pca__n_components=161, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0, pca__n_components=161, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0, pca__n_components=161, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0, pca__n_components=161, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0, pca__n_components=161, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=76, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=76, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=76, poly__degree=1, scaler=StandardScaler(); total time=   0.2s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=76, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=100, pca__n_components=76, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=41, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=41, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=41, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=41, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.1, pca__n_components=41, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=171, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=171, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=171, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=171, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=171, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=6, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=6, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=6, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=6, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=6, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=21, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=101, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=101, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=101, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=101, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.25, pca__n_components=101, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=71, poly__degree=3, scaler=MinMaxScaler(); total time= 1.5min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=71, poly__degree=3, scaler=MinMaxScaler(); total time= 1.5min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=71, poly__degree=3, scaler=MinMaxScaler(); total time= 1.5min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=71, poly__degree=3, scaler=MinMaxScaler(); total time= 1.5min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=0, pca__n_components=71, poly__degree=3, scaler=MinMaxScaler(); total time= 1.5min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=71, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.058e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=76, poly__degree=3, scaler=passthrough; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.887e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=76, poly__degree=3, scaler=passthrough; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.805e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=76, poly__degree=3, scaler=passthrough; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.805e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=76, poly__degree=3, scaler=passthrough; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.671e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.8, pca__n_components=76, poly__degree=3, scaler=passthrough; total time= 1.5min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=36, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=36, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=36, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=36, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=36, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=2, scaler=StandardScaler(); total time=   1.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=2, scaler=StandardScaler(); total time=   2.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=2, scaler=StandardScaler(); total time=   2.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=2, scaler=StandardScaler(); total time=   2.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=166, poly__degree=2, scaler=StandardScaler(); total time=   2.1s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=61, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=61, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=61, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=61, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=61, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.5, pca__n_components=121, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.25, pca__n_components=56, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.25, pca__n_components=56, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.25, pca__n_components=56, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.25, pca__n_components=56, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.25, pca__n_components=56, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=51, poly__degree=2, scaler=StandardScaler(); total time=   1.5s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=51, poly__degree=2, scaler=StandardScaler(); total time=   1.4s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=51, poly__degree=2, scaler=StandardScaler(); total time=   1.3s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=51, poly__degree=2, scaler=StandardScaler(); total time=   1.3s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=51, poly__degree=2, scaler=StandardScaler(); total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.248e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=3, scaler=StandardScaler(); total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.183e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=3, scaler=StandardScaler(); total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.914e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=3, scaler=StandardScaler(); total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.062e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=3, scaler=StandardScaler(); total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.822e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=3, scaler=StandardScaler(); total time= 1.2min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=66, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=66, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=66, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=66, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=66, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=41, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=41, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=41, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=41, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=1, pca__n_components=41, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.8, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.8s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=131, poly__degree=2, scaler=passthrough; total time=   2.3s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=131, poly__degree=2, scaler=passthrough; total time=   3.1s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=131, poly__degree=2, scaler=passthrough; total time=   2.4s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=131, poly__degree=2, scaler=passthrough; total time=   2.7s\n",
      "[CV] END classifier=Lasso(), classifier__alpha=0.25, pca__n_components=131, poly__degree=2, scaler=passthrough; total time=   2.4s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=116, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=116, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=116, poly__degree=1, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=116, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=116, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=91, poly__degree=3, scaler=MinMaxScaler(); total time= 1.8min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=91, poly__degree=3, scaler=MinMaxScaler(); total time= 1.8min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=91, poly__degree=3, scaler=MinMaxScaler(); total time= 1.8min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=91, poly__degree=3, scaler=MinMaxScaler(); total time= 1.8min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=91, poly__degree=3, scaler=MinMaxScaler(); total time= 1.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=161, poly__degree=2, scaler=MinMaxScaler(); total time=   2.5s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=161, poly__degree=2, scaler=MinMaxScaler(); total time=   3.4s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=161, poly__degree=2, scaler=MinMaxScaler(); total time=   2.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=161, poly__degree=2, scaler=MinMaxScaler(); total time=   2.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=161, poly__degree=2, scaler=MinMaxScaler(); total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.560e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=1, poly__degree=3, scaler=StandardScaler(); total time=  37.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=1, poly__degree=3, scaler=StandardScaler(); total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=1, poly__degree=3, scaler=StandardScaler(); total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.315e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=1, poly__degree=3, scaler=StandardScaler(); total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.106e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.25, pca__n_components=1, poly__degree=3, scaler=StandardScaler(); total time=  39.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=0.8, pca__n_components=46, poly__degree=3, scaler=passthrough; total time= 1.1min\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=100, pca__n_components=131, poly__degree=4, scaler=passthrough; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=161, poly__degree=3, scaler=passthrough; total time= 2.8min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=36, poly__degree=2, scaler=StandardScaler(); total time=   1.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=36, poly__degree=2, scaler=StandardScaler(); total time=   1.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=36, poly__degree=2, scaler=StandardScaler(); total time=   1.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=36, poly__degree=2, scaler=StandardScaler(); total time=   0.9s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.1, pca__n_components=36, poly__degree=2, scaler=StandardScaler(); total time=   1.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=36, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=36, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=36, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=36, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=36, poly__degree=5, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.5, pca__n_components=141, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.5, pca__n_components=141, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.5, pca__n_components=141, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.5, pca__n_components=141, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.5, pca__n_components=141, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.7s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.25, pca__n_components=11, poly__degree=2, scaler=passthrough; total time=   0.8s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.1, pca__n_components=116, poly__degree=5, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.75, pca__n_components=56, poly__degree=2, scaler=MinMaxScaler(); total time=   1.4s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.75, pca__n_components=56, poly__degree=2, scaler=MinMaxScaler(); total time=   1.4s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.75, pca__n_components=56, poly__degree=2, scaler=MinMaxScaler(); total time=   1.3s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.75, pca__n_components=56, poly__degree=2, scaler=MinMaxScaler(); total time=   1.4s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=75, classifier__l1_ratio=0.75, pca__n_components=56, poly__degree=2, scaler=MinMaxScaler(); total time=   1.5s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=56, poly__degree=2, scaler=passthrough; total time=   1.3s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=56, poly__degree=2, scaler=passthrough; total time=   1.3s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=56, poly__degree=2, scaler=passthrough; total time=   1.2s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=56, poly__degree=2, scaler=passthrough; total time=   1.3s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=0.5, pca__n_components=56, poly__degree=2, scaler=passthrough; total time=   1.2s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=1, pca__n_components=136, poly__degree=3, scaler=passthrough; total time= 2.4min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=1, pca__n_components=136, poly__degree=3, scaler=passthrough; total time= 2.4min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=1, pca__n_components=136, poly__degree=3, scaler=passthrough; total time= 2.4min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=1, pca__n_components=136, poly__degree=3, scaler=passthrough; total time= 2.4min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=1, pca__n_components=136, poly__degree=3, scaler=passthrough; total time= 2.4min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=36, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=36, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=36, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=36, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=100, classifier__l1_ratio=1, pca__n_components=36, poly__degree=1, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=31, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=31, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=31, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=31, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.75, pca__n_components=31, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=41, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=41, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=41, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=41, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.8, pca__n_components=41, poly__degree=4, scaler=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=11, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=11, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=11, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=11, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=75, pca__n_components=11, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=161, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=161, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=161, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=161, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=Ridge(), classifier__alpha=1, pca__n_components=161, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=4, scaler=passthrough; total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.8, pca__n_components=116, poly__degree=4, scaler=passthrough; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.847e+04, tolerance: 1.113e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=41, poly__degree=3, scaler=MinMaxScaler(); total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.696e+04, tolerance: 1.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=41, poly__degree=3, scaler=MinMaxScaler(); total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.632e+04, tolerance: 1.044e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=41, poly__degree=3, scaler=MinMaxScaler(); total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.653e+04, tolerance: 1.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=41, poly__degree=3, scaler=MinMaxScaler(); total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.511e+04, tolerance: 1.022e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=ElasticNet(), classifier__alpha=0, classifier__l1_ratio=0.5, pca__n_components=41, poly__degree=3, scaler=MinMaxScaler(); total time= 1.1min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.9, classifier__l1_ratio=0.1, pca__n_components=51, poly__degree=4, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=1, classifier__l1_ratio=0.75, pca__n_components=76, poly__degree=3, scaler=StandardScaler(); total time= 1.6min\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=96, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=96, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=96, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=96, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=ElasticNet(), classifier__alpha=0.25, classifier__l1_ratio=1, pca__n_components=96, poly__degree=5, scaler=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "225 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 517, in transform\n",
      "    XP = np.empty(\n",
      "        shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "    )\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 16.2 TiB for an array with shape (1626, 1367533859) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 517, in transform\n",
      "    XP = np.empty(\n",
      "        shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "    )\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 16.2 TiB for an array with shape (1627, 1367533859) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 517, in transform\n",
      "    XP = np.empty(\n",
      "        shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "    )\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 468. GiB for an array with shape (1626, 38630899) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 517, in transform\n",
      "    XP = np.empty(\n",
      "        shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "    )\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 468. GiB for an array with shape (1627, 38630899) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-6.08241917 -6.31485276         nan -6.31485276         nan         nan\n",
      "         nan -5.36296679         nan         nan         nan -5.7207826\n",
      "         nan -5.73174628 -5.35038221 -5.94445475 -5.59692531         nan\n",
      " -5.67288533         nan         nan -5.70346868         nan         nan\n",
      " -5.69836773 -5.47353663 -6.31485276         nan -6.14767407 -6.12201058\n",
      "         nan -5.9446952          nan -5.89536898         nan -5.82943948\n",
      "         nan         nan -5.68942021         nan -6.31389057 -5.61222061\n",
      "         nan -5.25130943 -5.33905277         nan -5.82943948 -5.30301106\n",
      "         nan -5.37915333         nan -5.93681229 -6.30431297         nan\n",
      "         nan -6.31485276 -6.30221111         nan         nan -5.51717342\n",
      "         nan -5.24582076         nan -5.57120545         nan -6.31485276\n",
      "         nan         nan -6.31485276 -6.06328162 -6.27165868         nan\n",
      " -5.56441224 -5.72335317 -5.42866027 -6.31485276 -5.27052019 -5.27332281\n",
      " -6.31382645 -5.56050533         nan -5.59690928 -6.28624473         nan\n",
      "         nan -5.72335265         nan -6.31485276 -5.42126225 -5.61302985\n",
      " -6.31485276         nan         nan         nan         nan         nan\n",
      " -5.27833252         nan -6.1496155          nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
      "                ('pca', PCA(n_components=np.int64(71))),\n",
      "                ('classifier', Ridge(alpha=0))])\n",
      "-5.245820759955924\n",
      "{'scaler': MinMaxScaler(), 'poly__degree': 3, 'pca__n_components': np.int64(71), 'classifier__alpha': 0, 'classifier': Ridge()}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes.drop('y', axis=1)\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('pca', PCA(n_components=100)),\n",
    "    ('classifier', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_params = {\n",
    "    'scaler':[MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'poly__degree':[1],\n",
    "    'pca__n_components':np.arange(1, 172, 5),\n",
    "    'classifier': [LinearRegression()]\n",
    "}\n",
    "\n",
    "regularizacion_params = {\n",
    "    'scaler': [MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'poly__degree':[1, 2, 3, 4, 5],\n",
    "    'pca__n_components':np.arange(1, 172, 5),\n",
    "    'classifier': [Ridge(), Lasso()],\n",
    "    'classifier__alpha': [0.25, 0,75, 0.90, 1, 100]\n",
    "}\n",
    "\n",
    "elastic_param = {\n",
    "    'scaler': [MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'poly__degree':[1, 2, 3, 4, 5],\n",
    "    'pca__n_components':np.arange(1, 172, 5),\n",
    "    'classifier': [ElasticNet()],\n",
    "    'classifier__alpha': [0.25, 0,75, 0.90, 1, 100],\n",
    "    'classifier__l1_ratio': [0.1, 0.25, 0.50, 0.75, 0.80, 1]\n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    linear_params,\n",
    "    regularizacion_params,\n",
    "    elastic_param\n",
    "]\n",
    "\n",
    "clf2 = RandomizedSearchCV(estimator = pipe,\n",
    "                  param_distributions = search_space,\n",
    "                  n_iter=100,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 5,\n",
    "                  verbose=2)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "print(clf2.best_estimator_)\n",
    "print(clf2.best_score_)\n",
    "print(clf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1599ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.0601442703441455\n",
      "MAPE test 0.3520906381606369\n",
      "MSE test 41.27723167736816\n",
      "RMSE test 6.42473592277287\n",
      "R2 score 0.31507579193914714\n"
     ]
    }
   ],
   "source": [
    "best2 = clf2.best_estimator_\n",
    "predictions_best2 = best2.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best2))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best2))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best2))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best2)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52858ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/2_ridge_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best2, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233df388",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21735c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karli\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 18 is smaller than n_iter=150. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', 'passthrough'), ('pca', PCA(n_components=104)),\n",
      "                ('classifier',\n",
      "                 RandomForestRegressor(max_depth=10, min_samples_leaf=20,\n",
      "                                       random_state=42))])\n",
      "-5.1237277382022475\n",
      "{'scaler': 'passthrough', 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 10, 'classifier': RandomForestRegressor(random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes.drop('y', axis=1)\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=104)),\n",
    "    ('classifier', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "rf_params = {\n",
    "    'scaler': [MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'classifier': [RandomForestRegressor(random_state=42)],\n",
    "    'classifier__max_depth': [7, 5, 10],\n",
    "    'classifier__min_samples_leaf': [20, 30]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    rf_params\n",
    "]\n",
    "\n",
    "clf  = RandomizedSearchCV(estimator = pipe,\n",
    "                  param_distributions= search_space,\n",
    "                  n_iter= 150,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3240432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11705673 0.12726154 0.01540085 0.00352184 0.00886677 0.00667969\n",
      " 0.00209989 0.00528339 0.0033973  0.0029698  0.00583565 0.00775611\n",
      " 0.00255515 0.00247216 0.01066868 0.21127753 0.01591742 0.00580578\n",
      " 0.02606705 0.0588527  0.00647696 0.01264301 0.01714871 0.005765\n",
      " 0.00565056 0.01255987 0.01109874 0.00637508 0.0067054  0.00897316\n",
      " 0.00775487 0.00247513 0.00239825 0.00388465 0.00298157 0.00748951\n",
      " 0.00415118 0.00345798 0.00395436 0.0059711  0.00379282 0.00362848\n",
      " 0.00266794 0.00312955 0.00246715 0.00325625 0.00326978 0.00205561\n",
      " 0.00288698 0.00754531 0.00489576 0.00199871 0.00253758 0.00138319\n",
      " 0.00226819 0.00163202 0.00295794 0.00232464 0.00300753 0.00189977\n",
      " 0.0026164  0.00317404 0.00208828 0.0027764  0.00226719 0.00114753\n",
      " 0.008643   0.00261082 0.00197635 0.01033944 0.00303457 0.00769186\n",
      " 0.00908294 0.00267035 0.00231703 0.00376911 0.00563454 0.00218209\n",
      " 0.00391954 0.00201087 0.00487494 0.00376038 0.00272441 0.00554069\n",
      " 0.00490353 0.00461545 0.00162261 0.00287112 0.0019495  0.00371989\n",
      " 0.00313003 0.00269394 0.00274651 0.00264311 0.00261198 0.00297957\n",
      " 0.0026179  0.00692153 0.00512367 0.00445725 0.00388959 0.00240404\n",
      " 0.0021808  0.00179886]\n",
      "Index(['lat', 'lon', 'dine_in', 'price_level', 'reservable', 'serves_beer',\n",
      "       'serves_breakfast', 'serves_brunch', 'serves_dinner', 'serves_lunch',\n",
      "       ...\n",
      "       'Universidad', 'Valdeacederas', 'Valdefuentes', 'Valdezarza',\n",
      "       'Vallehermoso', 'Valverde', 'Ventas', 'Vista Alegre', 'Zofo',\n",
      "       'tipo_cocina_encoder'],\n",
      "      dtype='object', length=176)\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "425dbeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.05098047620047\n",
      "MAPE test 0.34651323761188374\n",
      "MSE test 40.96849594417946\n",
      "RMSE test 6.400663711223975\n",
      "R2 score 0.3201987270043466\n"
     ]
    }
   ],
   "source": [
    "best1 = clf.best_estimator_\n",
    "predictions_best1 = best1.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best1))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best1))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best1))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best1)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "186c3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/1_randomforest_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best1, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60982e68",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9264d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', 'passthrough'),\n",
      "                ('classifier',\n",
      "                 GradientBoostingRegressor(learning_rate=0.25,\n",
      "                                           min_samples_leaf=40,\n",
      "                                           random_state=42))])\n",
      "-5.148710540235394\n",
      "{'classifier': GradientBoostingRegressor(random_state=42), 'classifier__learning_rate': 0.25, 'classifier__max_depth': 3, 'classifier__min_samples_leaf': 40, 'classifier__n_estimators': 100, 'scaler': 'passthrough'}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes[['serves_breakfast', \n",
    "                  'tasa_parados', \n",
    "                  'dur_media_credito_viviendas', \n",
    "                  'poblacion_80_mas',\n",
    "                  'poblacion_china',\n",
    "                  'pct_crecimiento_demografico',\n",
    "                  'rating_mean',\n",
    "                  'poblacion_italia',\n",
    "                  'user_ratings_mean',\n",
    "                  'price_level',\n",
    "                  'tipo_cocina_encoder',\n",
    "                  'cod_barrio'\n",
    "                  ]]\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GradientBoostingRegressor(random_state=42))])\n",
    "\n",
    "gboost_param = {\n",
    "    'scaler': [StandardScaler(), 'passthrough'],\n",
    "    'classifier': [GradientBoostingRegressor(random_state=42)],\n",
    "    'classifier__learning_rate': [0.25, 0.3, 0.5],\n",
    "    'classifier__max_depth': [3, 4],\n",
    "    'classifier__min_samples_leaf': [20, 30, 40],\n",
    "    'classifier__n_estimators':[100]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    gboost_param\n",
    "]\n",
    "\n",
    "clf3 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=3)\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "print(clf3.best_estimator_)\n",
    "print(clf3.best_score_)\n",
    "print(clf3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "275552b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06282067 0.02590067 0.01202272 0.03550269 0.00720897 0.01821853\n",
      " 0.08220218 0.0621866  0.18411932 0.44264033 0.02660307 0.04057425]\n",
      "Index(['serves_breakfast', 'tasa_parados', 'dur_media_credito_viviendas',\n",
      "       'poblacion_80_mas', 'poblacion_china', 'pct_crecimiento_demografico',\n",
      "       'rating_mean', 'poblacion_italia', 'user_ratings_mean', 'price_level',\n",
      "       'tipo_cocina_encoder', 'cod_barrio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clf3.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "655efd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.08366745233101\n",
      "MAPE test 0.3542661315136399\n",
      "MSE test 42.50152862781548\n",
      "RMSE test 6.519319644549996\n",
      "R2 score 0.29476070332635573\n"
     ]
    }
   ],
   "source": [
    "best3 = clf3.best_estimator_\n",
    "predictions_best3 = best3.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best3))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best3))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best3))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best3)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67aba27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/3_gradient_boost_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best3, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb2275",
   "metadata": {},
   "source": [
    "# Xboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbdb00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Pipeline(steps=[('select_features',\n",
      "                 SelectKBest(k='all',\n",
      "                             score_func=<function f_regression at 0x0000027DE7DB5A80>)),\n",
      "                ('classifier',\n",
      "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "                              colsample_bylevel=None, colsample_bynode=None,\n",
      "                              colsample_bytree=None, device=None,\n",
      "                              early_stopping_rounds=None,\n",
      "                              enable_categorical=False, eval_metric=None,\n",
      "                              feature_types=None, f...ghts=None,\n",
      "                              gamma=None, grow_policy=None,\n",
      "                              importance_type=None,\n",
      "                              interaction_constraints=None, learning_rate=0.25,\n",
      "                              max_bin=None, max_cat_threshold=None,\n",
      "                              max_cat_to_onehot=None, max_delta_step=None,\n",
      "                              max_depth=4, max_leaves=None, min_child_weight=5,\n",
      "                              missing=nan, monotone_constraints=None,\n",
      "                              multi_strategy=None, n_estimators=100,\n",
      "                              n_jobs=None, num_parallel_tree=None, ...))])\n",
      "-4.893934362158236\n",
      "{'classifier__learning_rate': 0.25, 'classifier__max_depth': 4, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 100, 'select_features__k': 'all'}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes.drop('y', axis=1)\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('select_features', SelectKBest(score_func=f_regression)),\n",
    "    ('classifier', xgboost.XGBRegressor())])\n",
    "\n",
    "xboost_param = {\n",
    "    'select_features__k':[50, 100, 120, 'all'],\n",
    "    'classifier__learning_rate': [0.25, 0.75, 1],\n",
    "    'classifier__max_depth': [4, 5, 6, 7],\n",
    "    'classifier__min_child_weight': [4, 5, 7],\n",
    "    'classifier__n_estimators':[100]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    xboost_param\n",
    "]\n",
    "\n",
    "clf4 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=3)\n",
    "\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print(clf4.best_estimator_)\n",
    "print(clf4.best_score_)\n",
    "print(clf4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f5b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05448301 0.04342006 0.01170791 0.00535932 0.01161539 0.02621751\n",
      " 0.00281791 0.01098142 0.00703253 0.00555892 0.00673646 0.00914079\n",
      " 0.00870098 0.00543663 0.01187231 0.05595296 0.01417166 0.00716517\n",
      " 0.01304254 0.02140538 0.01118424 0.00614812 0.02505677 0.00632774\n",
      " 0.00535607 0.01041254 0.01382921 0.00360219 0.01458952 0.00770539\n",
      " 0.00653169 0.0078293  0.01099748 0.00610852 0.00526752 0.01856276\n",
      " 0.00613491 0.00725096 0.00597583 0.0113606  0.00802727 0.00595477\n",
      " 0.00238882 0.00537988 0.00843489 0.00852711 0.01217137 0.00529872\n",
      " 0.00974892 0.01013396 0.00709702 0.00807458 0.00355549 0.00583404\n",
      " 0.00518821 0.00785551 0.0051204  0.0108516  0.01133472 0.0038774\n",
      " 0.01197184 0.01556842 0.00725678 0.00860488 0.00561377 0.00824463\n",
      " 0.00849354 0.00903673 0.00233407 0.02972311 0.00524215 0.00717178\n",
      " 0.00767631 0.00337085 0.01091161 0.00608742 0.00813173 0.00788212\n",
      " 0.00715408 0.00953597 0.00446072 0.00760627 0.00311008 0.01482668\n",
      " 0.01091979 0.00317664 0.00803535 0.00884646 0.00622695 0.00498054\n",
      " 0.00774754 0.00669425 0.00995091 0.00484223 0.00781539 0.00645022\n",
      " 0.00772565 0.00870721 0.01501656 0.00494381]\n",
      "Index(['lat', 'lon', 'dine_in', 'price_level', 'reservable', 'serves_beer',\n",
      "       'serves_breakfast', 'serves_brunch', 'serves_dinner', 'serves_lunch',\n",
      "       ...\n",
      "       'Universidad', 'Valdeacederas', 'Valdefuentes', 'Valdezarza',\n",
      "       'Vallehermoso', 'Valverde', 'Ventas', 'Vista Alegre', 'Zofo',\n",
      "       'tipo_cocina_encoder'],\n",
      "      dtype='object', length=176)\n"
     ]
    }
   ],
   "source": [
    "print(clf4.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d54b5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 5.283738803446602\n",
      "MAPE test 0.34878801669607584\n",
      "MSE test 44.7541604799365\n",
      "RMSE test 6.689855041773066\n",
      "R2 score 0.257382177086366\n"
     ]
    }
   ],
   "source": [
    "best4 = clf4.best_estimator_\n",
    "predictions_best4 = best4.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best4))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best4))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best4))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best4)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8931ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/4_xboost_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best4, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e15fbc",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b4ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('classifier', SVR(C=10, kernel='poly', max_iter=500000))])\n",
      "-4.897241058747725\n",
      "{'classifier__C': 10, 'classifier__degree': 3, 'classifier__gamma': 'scale', 'classifier__kernel': 'poly', 'classifier__max_iter': 500000, 'scaler': MinMaxScaler()}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes.drop(['y', 'cod_distrito', 'tipo_cocina_encoder', 'cod_barrio'], axis=1)\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVR())])\n",
    "\n",
    "SVR_param = {\n",
    "    'scaler': [MinMaxScaler(), StandardScaler()],\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto'],\n",
    "    'classifier__degree': [2, 3, 4, 5],\n",
    "    'classifier__C':[0.5, 1, 10, 50, 100],\n",
    "    'classifier__max_iter': [1000000]\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [\n",
    "    SVR_param\n",
    "]\n",
    "\n",
    "clf5 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "print(clf5.best_estimator_)\n",
    "print(clf5.best_score_)\n",
    "print(clf5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13e29504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 4.653434656363074\n",
      "MAPE test 0.3266049534036448\n",
      "MSE test 36.95694929247194\n",
      "RMSE test 6.07922275397702\n",
      "R2 score 0.3867633996305495\n"
     ]
    }
   ],
   "source": [
    "best5 = clf5.best_estimator_\n",
    "predictions_best5 = best5.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best5))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best5))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best5))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best5)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e9bb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/final_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best5, archivo_salida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7bead",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f599928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 7.8842772\ttotal: 5.46ms\tremaining: 541ms\n",
      "1:\tlearn: 7.6956730\ttotal: 9.7ms\tremaining: 475ms\n",
      "2:\tlearn: 7.5179772\ttotal: 14.7ms\tremaining: 474ms\n",
      "3:\tlearn: 7.3795071\ttotal: 19ms\tremaining: 456ms\n",
      "4:\tlearn: 7.2342170\ttotal: 23.5ms\tremaining: 446ms\n",
      "5:\tlearn: 7.1223240\ttotal: 27.7ms\tremaining: 433ms\n",
      "6:\tlearn: 7.0255973\ttotal: 32.4ms\tremaining: 431ms\n",
      "7:\tlearn: 6.9328243\ttotal: 36.7ms\tremaining: 422ms\n",
      "8:\tlearn: 6.8449508\ttotal: 41.1ms\tremaining: 415ms\n",
      "9:\tlearn: 6.7760732\ttotal: 45.5ms\tremaining: 409ms\n",
      "10:\tlearn: 6.7105825\ttotal: 49.7ms\tremaining: 402ms\n",
      "11:\tlearn: 6.6435156\ttotal: 53.7ms\tremaining: 394ms\n",
      "12:\tlearn: 6.5974678\ttotal: 57.7ms\tremaining: 386ms\n",
      "13:\tlearn: 6.5562891\ttotal: 62.8ms\tremaining: 386ms\n",
      "14:\tlearn: 6.5142969\ttotal: 67.6ms\tremaining: 383ms\n",
      "15:\tlearn: 6.4761188\ttotal: 72.3ms\tremaining: 380ms\n",
      "16:\tlearn: 6.4502704\ttotal: 76.4ms\tremaining: 373ms\n",
      "17:\tlearn: 6.4026112\ttotal: 80.7ms\tremaining: 368ms\n",
      "18:\tlearn: 6.3624132\ttotal: 84.9ms\tremaining: 362ms\n",
      "19:\tlearn: 6.3370243\ttotal: 89ms\tremaining: 356ms\n",
      "20:\tlearn: 6.2959913\ttotal: 93.7ms\tremaining: 353ms\n",
      "21:\tlearn: 6.2705042\ttotal: 97.8ms\tremaining: 347ms\n",
      "22:\tlearn: 6.2450466\ttotal: 102ms\tremaining: 341ms\n",
      "23:\tlearn: 6.2208049\ttotal: 106ms\tremaining: 336ms\n",
      "24:\tlearn: 6.1918471\ttotal: 111ms\tremaining: 333ms\n",
      "25:\tlearn: 6.1681391\ttotal: 115ms\tremaining: 327ms\n",
      "26:\tlearn: 6.1464921\ttotal: 119ms\tremaining: 322ms\n",
      "27:\tlearn: 6.1243480\ttotal: 123ms\tremaining: 317ms\n",
      "28:\tlearn: 6.1040468\ttotal: 128ms\tremaining: 312ms\n",
      "29:\tlearn: 6.0767070\ttotal: 132ms\tremaining: 307ms\n",
      "30:\tlearn: 6.0617181\ttotal: 136ms\tremaining: 303ms\n",
      "31:\tlearn: 6.0418591\ttotal: 141ms\tremaining: 299ms\n",
      "32:\tlearn: 6.0315638\ttotal: 145ms\tremaining: 295ms\n",
      "33:\tlearn: 6.0133101\ttotal: 149ms\tremaining: 290ms\n",
      "34:\tlearn: 5.9980393\ttotal: 153ms\tremaining: 285ms\n",
      "35:\tlearn: 5.9802334\ttotal: 158ms\tremaining: 282ms\n",
      "36:\tlearn: 5.9622369\ttotal: 163ms\tremaining: 277ms\n",
      "37:\tlearn: 5.9396259\ttotal: 167ms\tremaining: 272ms\n",
      "38:\tlearn: 5.9303094\ttotal: 171ms\tremaining: 267ms\n",
      "39:\tlearn: 5.9149696\ttotal: 176ms\tremaining: 263ms\n",
      "40:\tlearn: 5.9021458\ttotal: 181ms\tremaining: 260ms\n",
      "41:\tlearn: 5.8801779\ttotal: 185ms\tremaining: 255ms\n",
      "42:\tlearn: 5.8666663\ttotal: 189ms\tremaining: 251ms\n",
      "43:\tlearn: 5.8478564\ttotal: 193ms\tremaining: 246ms\n",
      "44:\tlearn: 5.8365306\ttotal: 198ms\tremaining: 242ms\n",
      "45:\tlearn: 5.8221182\ttotal: 203ms\tremaining: 238ms\n",
      "46:\tlearn: 5.8092610\ttotal: 209ms\tremaining: 235ms\n",
      "47:\tlearn: 5.7960874\ttotal: 213ms\tremaining: 231ms\n",
      "48:\tlearn: 5.7837199\ttotal: 217ms\tremaining: 226ms\n",
      "49:\tlearn: 5.7715089\ttotal: 223ms\tremaining: 223ms\n",
      "50:\tlearn: 5.7578748\ttotal: 228ms\tremaining: 220ms\n",
      "51:\tlearn: 5.7406116\ttotal: 236ms\tremaining: 218ms\n",
      "52:\tlearn: 5.7291481\ttotal: 241ms\tremaining: 214ms\n",
      "53:\tlearn: 5.7146772\ttotal: 246ms\tremaining: 210ms\n",
      "54:\tlearn: 5.7040975\ttotal: 252ms\tremaining: 207ms\n",
      "55:\tlearn: 5.6919178\ttotal: 258ms\tremaining: 203ms\n",
      "56:\tlearn: 5.6802995\ttotal: 265ms\tremaining: 200ms\n",
      "57:\tlearn: 5.6640050\ttotal: 272ms\tremaining: 197ms\n",
      "58:\tlearn: 5.6525265\ttotal: 278ms\tremaining: 193ms\n",
      "59:\tlearn: 5.6443041\ttotal: 284ms\tremaining: 189ms\n",
      "60:\tlearn: 5.6347846\ttotal: 289ms\tremaining: 185ms\n",
      "61:\tlearn: 5.6210468\ttotal: 294ms\tremaining: 180ms\n",
      "62:\tlearn: 5.6088372\ttotal: 299ms\tremaining: 176ms\n",
      "63:\tlearn: 5.5993740\ttotal: 304ms\tremaining: 171ms\n",
      "64:\tlearn: 5.5868801\ttotal: 309ms\tremaining: 166ms\n",
      "65:\tlearn: 5.5775467\ttotal: 314ms\tremaining: 162ms\n",
      "66:\tlearn: 5.5733396\ttotal: 318ms\tremaining: 157ms\n",
      "67:\tlearn: 5.5682122\ttotal: 322ms\tremaining: 152ms\n",
      "68:\tlearn: 5.5598055\ttotal: 327ms\tremaining: 147ms\n",
      "69:\tlearn: 5.5524139\ttotal: 332ms\tremaining: 142ms\n",
      "70:\tlearn: 5.5424682\ttotal: 338ms\tremaining: 138ms\n",
      "71:\tlearn: 5.5360495\ttotal: 343ms\tremaining: 133ms\n",
      "72:\tlearn: 5.5266599\ttotal: 347ms\tremaining: 128ms\n",
      "73:\tlearn: 5.5208960\ttotal: 351ms\tremaining: 123ms\n",
      "74:\tlearn: 5.5140714\ttotal: 356ms\tremaining: 119ms\n",
      "75:\tlearn: 5.5016734\ttotal: 361ms\tremaining: 114ms\n",
      "76:\tlearn: 5.4920828\ttotal: 365ms\tremaining: 109ms\n",
      "77:\tlearn: 5.4733063\ttotal: 369ms\tremaining: 104ms\n",
      "78:\tlearn: 5.4615623\ttotal: 374ms\tremaining: 99.3ms\n",
      "79:\tlearn: 5.4551437\ttotal: 378ms\tremaining: 94.5ms\n",
      "80:\tlearn: 5.4401649\ttotal: 382ms\tremaining: 89.6ms\n",
      "81:\tlearn: 5.4305922\ttotal: 386ms\tremaining: 84.8ms\n",
      "82:\tlearn: 5.4183334\ttotal: 393ms\tremaining: 80.4ms\n",
      "83:\tlearn: 5.4021204\ttotal: 398ms\tremaining: 75.8ms\n",
      "84:\tlearn: 5.3967502\ttotal: 402ms\tremaining: 71ms\n",
      "85:\tlearn: 5.3875779\ttotal: 408ms\tremaining: 66.4ms\n",
      "86:\tlearn: 5.3780998\ttotal: 413ms\tremaining: 61.7ms\n",
      "87:\tlearn: 5.3737279\ttotal: 417ms\tremaining: 56.9ms\n",
      "88:\tlearn: 5.3654992\ttotal: 422ms\tremaining: 52.1ms\n",
      "89:\tlearn: 5.3545234\ttotal: 426ms\tremaining: 47.4ms\n",
      "90:\tlearn: 5.3407522\ttotal: 431ms\tremaining: 42.7ms\n",
      "91:\tlearn: 5.3289330\ttotal: 436ms\tremaining: 37.9ms\n",
      "92:\tlearn: 5.3151134\ttotal: 440ms\tremaining: 33.1ms\n",
      "93:\tlearn: 5.3057812\ttotal: 444ms\tremaining: 28.3ms\n",
      "94:\tlearn: 5.2978355\ttotal: 448ms\tremaining: 23.6ms\n",
      "95:\tlearn: 5.2934758\ttotal: 452ms\tremaining: 18.8ms\n",
      "96:\tlearn: 5.2870755\ttotal: 456ms\tremaining: 14.1ms\n",
      "97:\tlearn: 5.2814849\ttotal: 460ms\tremaining: 9.39ms\n",
      "98:\tlearn: 5.2678624\ttotal: 465ms\tremaining: 4.69ms\n",
      "99:\tlearn: 5.2562296\ttotal: 469ms\tremaining: 0us\n",
      "Pipeline(steps=[('scaler', 'passthrough'),\n",
      "                ('rfe',\n",
      "                 RFE(estimator=LinearRegression(), n_features_to_select=40)),\n",
      "                ('pca', PCA(n_components=20)),\n",
      "                ('classifier',\n",
      "                 <catboost.core.CatBoostRegressor object at 0x0000027DF12003B0>)])\n",
      "-4.925450550021632\n",
      "{'classifier__depth': 6, 'classifier__iterations': 100, 'classifier__learning_rate': 0.1, 'pca__n_components': 20, 'rfe__n_features_to_select': 40, 'scaler': 'passthrough'}\n"
     ]
    }
   ],
   "source": [
    "X = restaurantes.drop(list(restaurantes.iloc[:, 57:172].columns)+['y'], axis=1)\n",
    "\n",
    "y = restaurantes['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('rfe', RFE(estimator=LinearRegression(), n_features_to_select=30)),\n",
    "    ('pca', PCA(n_components=15)),  \n",
    "    ('classifier', CatBoostRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "cat_grid = {\n",
    "    'scaler':[MinMaxScaler(), StandardScaler(), 'passthrough'],\n",
    "    'rfe__n_features_to_select': [20, 30, 40],\n",
    "    'pca__n_components': [10, 15, 20],\n",
    "    'classifier__depth': [4, 6],\n",
    "    'classifier__learning_rate': [0.03, 0.1],\n",
    "    'classifier__iterations': [100, 200]\n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    cat_grid\n",
    "]\n",
    "\n",
    "clf6 = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  cv = 3,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf6.fit(X_train, y_train)\n",
    "\n",
    "print(clf6.best_estimator_)\n",
    "print(clf6.best_score_)\n",
    "print(clf6.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e01eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test 4.956151165587531\n",
      "MAPE test 0.33489489288503793\n",
      "MSE test 40.95015393064442\n",
      "RMSE test 6.399230729599021\n",
      "R2 score 0.3205030809686077\n"
     ]
    }
   ],
   "source": [
    "best6 = clf6.best_estimator_\n",
    "predictions_best6 = best6.predict(X_test)\n",
    "\n",
    "print(\"MAE test\", mean_absolute_error(y_test, predictions_best6))\n",
    "print(\"MAPE test\", mean_absolute_percentage_error(y_test, predictions_best6))\n",
    "print(\"MSE test\", mean_squared_error(y_test, predictions_best6))\n",
    "print(\"RMSE test\", mean_squared_error(y_test, predictions_best6)**(1/2))\n",
    "print(\"R2 score\", r2_score(y_test, predictions_best6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3c6bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/6_catboost_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best3, archivo_salida)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
